{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7139914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/fraud_transactions.csv\")\n",
    "X = df.drop('fraud_flag', axis=1)\n",
    "y = df['fraud_flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a05c1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# currency conversion\n",
    "class CurrencyConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rates=None, base_currency=\"INR\"):\n",
    "        if rates is None:\n",
    "            rates = {\"INR\": 1.0, \"USD\": 83.0, \"EUR\": 90.0}\n",
    "        self.rates = rates\n",
    "        self.base_currency = base_currency\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"amount_converted\"] = X.apply(\n",
    "            lambda row: row[\"amount\"] * self.rates.get(row[\"currency\"], 1.0), axis=1\n",
    "        )\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"Add 'amount_converted' to the feature names\"\"\"\n",
    "        if input_features is None:\n",
    "            input_features = []\n",
    "        # Return original features + new feature\n",
    "        output_features = list(input_features) + ['amount_converted']\n",
    "        return np.asarray(output_features, dtype=object)\n",
    "\n",
    "\n",
    "# typo fixing   \n",
    "class TypoFixer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column='merchant_category', typo_map=None):\n",
    "        if typo_map is None:\n",
    "            typo_map = {'Groceires': 'Groceries'}\n",
    "        self.column = column\n",
    "        self.typo_map = typo_map\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if self.column in X.columns:\n",
    "            X[self.column] = X[self.column].replace(self.typo_map)\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"Feature names unchanged - just fixing typos\"\"\"\n",
    "        if input_features is None:\n",
    "            return np.array([self.column], dtype=object)\n",
    "        return np.asarray(input_features, dtype=object)\n",
    "    \n",
    "\n",
    "# outlier clipping\n",
    "class OutlierClipper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=None, lower_quantile=0.01, upper_quantile=0.99):\n",
    "        self.features = features\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "        self.bounds = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.features:\n",
    "            q_low = X[col].quantile(self.lower_quantile)\n",
    "            q_high = X[col].quantile(self.upper_quantile)\n",
    "            self.bounds[col] = (q_low, q_high)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, (low, high) in self.bounds.items():\n",
    "            X[col] = X[col].clip(lower=low, upper=high)\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"Feature names unchanged - just clipping values\"\"\"\n",
    "        if input_features is None:\n",
    "            return np.asarray(self.features, dtype=object)\n",
    "        return np.asarray(input_features, dtype=object)\n",
    "    \n",
    "\n",
    "# Define Feature Groups\n",
    "num_features = [\n",
    "    \"amount_converted\", \"velocity\", \"ip_risk_score\", \"customer_age\",\n",
    "    \"account_tenure\", \"geo_distance\", \"merchant_risk_score\", \"failed_login_attempts\"\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    \"currency\", \"merchant_category\", \"transaction_type\", \"channel\", \"location\"\n",
    "]\n",
    "\n",
    "bin_features = [\"card_present\", \"is_international\"]\n",
    "\n",
    "\n",
    "# Pipelines for Each Feature Type\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    (\"outlier_clipper\", OutlierClipper(features=num_features)),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"typo_fixer\", TypoFixer()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "cat_pipeline_catboost = Pipeline([\n",
    "    (\"typo fixer\", TypoFixer()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\"))\n",
    "])\n",
    "\n",
    "# Binary pipeline\n",
    "bin_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\"))\n",
    "])\n",
    "\n",
    "\n",
    "# Full Preprocessing Pipeline\n",
    "preprocessor = Pipeline([\n",
    "    (\"currency_converter\", CurrencyConverter()),\n",
    "    (\"transformer\", ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_features),\n",
    "        (\"cat\", cat_pipeline, cat_features),\n",
    "        (\"bin\", bin_pipeline, bin_features)\n",
    "    ]))\n",
    "])\n",
    "\n",
    "preprocessor_catboost = Pipeline([\n",
    "    (\"currency_converter\", CurrencyConverter()),\n",
    "    (\"transformer\", ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_features),\n",
    "        (\"cat\", cat_pipeline_catboost, cat_features),\n",
    "        (\"bin\", bin_pipeline, bin_features)\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a55ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "\n",
      "Best F1 Score (CV): 0.8474077348318468\n",
      "\n",
      "Best Parameters:\n",
      "classifier__n_estimators: 200\n",
      "classifier__min_samples_split: 5\n",
      "classifier__min_samples_leaf: 4\n",
      "classifier__max_depth: 10\n",
      "\n",
      "train f1 score: 0.8512396694214877\n",
      "test f1 score: 0.8133704735376045\n",
      "\n",
      "Confusion Matrix [[TN FP]\n",
      "                  [FN TP]]:\n",
      "[[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "OOB Score: 0.99725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# Parameter Space\n",
    "# -----------------------------\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Base Model\n",
    "# -----------------------------\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Pipeline\n",
    "# -----------------------------\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', rf)\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Randomized Search\n",
    "# -----------------------------\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    refit=True   # refit best model automatically\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Train\n",
    "# -----------------------------\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# Best Model & Parameters\n",
    "# -----------------------------\n",
    "best_model_rf = random_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest F1 Score (CV):\", random_search.best_score_)\n",
    "print(\"\\nBest Parameters:\")\n",
    "for k, v in random_search.best_params_.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Train and Test Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "y_pred = best_model_rf.predict(X_train)\n",
    "print(\"\\ntrain f1 score:\", f1_score(y_train, y_pred))\n",
    "\n",
    "y_pred = best_model_rf.predict(X_test)\n",
    "print(\"test f1 score:\", f1_score(y_test, y_pred))\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\"\"\\nConfusion Matrix [[TN FP]\n",
    "                  [FN TP]]:\"\"\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# -----------------------------\n",
    "# OOB Score (Only if bootstrap=True)\n",
    "# -----------------------------\n",
    "rf_best = best_model_rf.named_steps['classifier']\n",
    "\n",
    "if rf_best.bootstrap:\n",
    "    print(\"\\nOOB Score:\", rf_best.oob_score_)\n",
    "else:\n",
    "    print(\"\\nOOB Score: Not available (bootstrap=False)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa286575",
   "metadata": {},
   "source": [
    "| Pattern           | Meaning              |\n",
    "| ----------------- | -------------------- |\n",
    "| Train ≫ CV ≈ Test | Overfitting          |\n",
    "| Train ≈ CV ≈ Test | Healthy              |\n",
    "| CV ≫ Test         | Data leakage / shift |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa051c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train f1 score: 0.8512396694214877\n",
      "test f1 score: 0.8133704735376045\n",
      "\n",
      "confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_depth=10,\n",
    "                            random_state=42, class_weight='balanced', n_jobs=-1, oob_score=True)\n",
    "\n",
    "rfp = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', rf)\n",
    "])\n",
    "\n",
    "rfp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfp.predict(X_train)\n",
    "print(\"train f1 score:\", f1_score(y_train, y_pred))\n",
    "\n",
    "y_prob = rfp.predict_proba(X_test)[:,1]\n",
    "y_pred = (y_prob >= 0.36).astype(int)     # best threshold = 0.36\n",
    "print(\"test f1 score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nconfusion_matrix:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d532625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test f1 score for threshold 0.36: 0.8133704735376045\n"
     ]
    }
   ],
   "source": [
    "y_prob = rfp.predict_proba(X_test)[:,1]\n",
    "l=-np.inf\n",
    "for i in range(100):\n",
    "    y_pred = (y_prob >= 0.01*i).astype(int)\n",
    "    if l<f1_score(y_test, y_pred):\n",
    "        l=f1_score(y_test, y_pred)\n",
    "        n=0.01*i\n",
    "\n",
    "print(f\"\\ntest f1 score for threshold {n}: {l}\")\n",
    "# print(\"correspondin confusion_matrix:\\n\",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a30252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Threshold Tuning\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "#     X_train, y_train,\n",
    "#     test_size=0.2,\n",
    "#     stratify=y_train,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# best_model_rf.fit(X_tr, y_tr)\n",
    "# y_val_probs = best_model_rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# from sklearn.metrics import precision_recall_curve\n",
    "# import numpy as np\n",
    "\n",
    "# precision, recall, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "\n",
    "# f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
    "# best_idx = np.argmax(f1_scores)\n",
    "\n",
    "# best_threshold = thresholds[best_idx]\n",
    "# best_f1 = f1_scores[best_idx]\n",
    "\n",
    "# print(\"Best threshold:\", best_threshold)\n",
    "# print(\"Validation F1:\", best_f1)\n",
    "\n",
    "# y_train_probs = best_model_rf.predict_proba(X_train)[:, 1]\n",
    "# y_train_pred = (y_train_probs >= best_threshold).astype(int)\n",
    "\n",
    "# y_test_probs = best_model_rf.predict_proba(X_test)[:, 1]\n",
    "# y_test_pred = (y_test_probs >= best_threshold).astype(int)\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "# print(\"\\nTrain F1:\", f1_score(y_train, y_train_pred))\n",
    "# print(\"Test F1:\", f1_score(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "# # Output:\n",
    "# # Best threshold: 0.7614023318402273\n",
    "# # Validation F1: 0.8591065287152962\n",
    "\n",
    "# # Train F1: 0.8498269896193772\n",
    "# # Test F1: 0.9870967741935484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ee19c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost Model:\n",
      "Best CV F1: 0.8610169491525423\n",
      "\n",
      "Best params: {'iterations': 800, 'learning_rate': 0.05, 'depth': 4, 'l2_leaf_reg': 5, 'loss_function': 'Logloss', 'verbose': 0, 'auto_class_weights': 'SqrtBalanced', 'eval_metric': 'F1', 'random_state': 42, 'cat_features': [8, 9, 10, 11, 12]}\n",
      "\n",
      "train f1 score: 0.8557758031442242\n",
      "test f1 score: 0.8133704735376045\n",
      "\n",
      "Confusion Matrix [[TN FP]\n",
      "                  [FN TP]]:\n",
      "[[19787    11]\n",
      " [   56   146]]\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import ParameterSampler, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "param_grid_catboost = {\n",
    "    \"iterations\": [200, 300, 500, 800],\n",
    "    \"depth\": [4, 6, 8, 10],\n",
    "    \"learning_rate\": [0.03, 0.05, 0.01, 0.1],\n",
    "    \"l2_leaf_reg\": [1, 3, 5]\n",
    "}\n",
    "\n",
    "best_score = -np.inf\n",
    "best_model_cb = None\n",
    "\n",
    "# transform training data\n",
    "X_train_cb = preprocessor_catboost.fit_transform(X_train)\n",
    "feature_names = preprocessor_catboost.named_steps[\"transformer\"].get_feature_names_out()\n",
    "X_train_df = pd.DataFrame(X_train_cb, columns=feature_names)\n",
    "\n",
    "# identify categorical features for CatBoost\n",
    "catboost_features = [col for col in X_train_df.columns.tolist() if col.startswith(\"cat_\")]\n",
    "catboost_features_idx = [X_train_df.columns.get_loc(col) for col in catboost_features]\n",
    "\n",
    "# transformm testing data\n",
    "X_test_cb = preprocessor_catboost.fit_transform(X_test)\n",
    "\n",
    "# stratified k-fold cv\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for params in ParameterSampler(param_grid_catboost, n_iter=5, random_state=42):\n",
    "    \n",
    "    cv_scores = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X_train_df, y_train):\n",
    "        X_train_cv, X_val_cv = X_train_df.iloc[train_index], X_train_df.iloc[val_index]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        **params,\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"F1\",\n",
    "        auto_class_weights='SqrtBalanced',\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "        cat_features=catboost_features_idx\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_cv, y_train_cv)\n",
    "    y_pred = model.predict(X_val_cv)\n",
    "\n",
    "    cv_scores.append(f1_score(y_val_cv, y_pred))\n",
    "\n",
    "    if np.mean(cv_scores) > best_score:\n",
    "        best_score = np.mean(cv_scores)\n",
    "        best_model_cb = model\n",
    "\n",
    "print(\"Best CatBoost Model:\")\n",
    "print(\"Best CV F1:\", best_score)\n",
    "print(\"\\nBest params:\", best_model_cb.get_params())\n",
    "\n",
    "# -----------------------------\n",
    "# Train and Test Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "y_pred = best_model_cb.predict(X_train_cb)\n",
    "print(\"\\ntrain f1 score:\", f1_score(y_train, y_pred))\n",
    "\n",
    "y_pred = best_model_cb.predict(X_test_cb)\n",
    "print(\"test f1 score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"\"\"\\nConfusion Matrix [[TN FP]\n",
    "                  [FN TP]]:\"\"\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d8b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting categorical features for catboost\n",
    "\n",
    "# X_train_cb = preprocessor_catboost.fit_transform(X_train)\n",
    "# feature_names = preprocessor_catboost.named_steps[\"transformer\"].get_feature_names_out()\n",
    "# X_train_df = pd.DataFrame(X_train_cb, columns=feature_names)\n",
    "# catboost_features = [col for col in X_train_df.columns.tolist() if col.startswith(\"cat_\")]\n",
    "# catboost_features_idx=[X_train_df.columns.get_loc(col) for col in catboost_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c8fa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train f1 score: 0.8577291381668947\n",
      "test f1 score: 0.8133704735376045\n",
      "\n",
      "confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n"
     ]
    }
   ],
   "source": [
    "cbp= CatBoostClassifier(\n",
    "    iterations=800,\n",
    "    learning_rate= 0.05, \n",
    "    depth= 4, \n",
    "    l2_leaf_reg= 5, \n",
    "    loss_function='Logloss', \n",
    "    verbose= 0, \n",
    "    auto_class_weights= 'SqrtBalanced', \n",
    "    eval_metric= 'F1', \n",
    "    random_state= 42, \n",
    "    cat_features= [8, 9, 10, 11, 12]\n",
    ")\n",
    "\n",
    "cbp.fit(X_train_cb, y_train)\n",
    "\n",
    "y_pred = cbp.predict(X_train_cb)\n",
    "print(\"train f1 score:\", f1_score(y_train, y_pred))\n",
    "\n",
    "y_prob = cbp.predict_proba(X_test_cb)[:,1]\n",
    "y_pred = (y_prob >= 0.45).astype(int)         # best threshold belongs to [0.4,0.5]\n",
    "print(\"test f1 score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nconfusion_matrix:\\n\",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb7ab033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test f1 score for threshold 0.40: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.41: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.42: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.43: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.44: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.45: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.46: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.47: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.48: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.49: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.50: 0.8133704735376045\n",
      "correspondin confusion_matrix:\n",
      " [[19787    11]\n",
      " [   56   146]]\n"
     ]
    }
   ],
   "source": [
    "y_prob = cbp.predict_proba(X_test_cb)[:,1]\n",
    "for i in range(40,51):\n",
    "    y_pred = (y_prob >= 0.01*i).astype(int)\n",
    "    print(f\"\\ntest f1 score for threshold {0.01*i:.2f}: {f1_score(y_test, y_pred)}\")\n",
    "    print(\"correspondin confusion_matrix:\\n\",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355ece4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# # -----------------------------\n",
    "# # Identify categorical features\n",
    "# # -----------------------------\n",
    "# X_trf = preprocessor_catboost.fit_transform(X_train)\n",
    "# feature_names = preprocessor_catboost.named_steps[\"transformer\"].get_feature_names_out()\n",
    "# X_train_cb = pd.DataFrame(X_trf, columns=feature_names)\n",
    "# cat_features = [col for col in X_train_cb.columns.tolist() if col.startswith(\"cat_\")]\n",
    "# cat_features_idx=[X_train_cb.columns.get_loc(col) for col in catboost_features]\n",
    "\n",
    "# # -----------------------------\n",
    "# # Transform X_test\n",
    "# # -----------------------------\n",
    "\n",
    "# X_test_transformed = preprocessor_catboost.transform(X_test)\n",
    "\n",
    "# # -----------------------------\n",
    "# # Base Model\n",
    "# # -----------------------------\n",
    "# cb = CatBoostClassifier(\n",
    "#     loss_function='Logloss',\n",
    "#     eval_metric='F1',\n",
    "#     auto_class_weights='SqrtBalanced',\n",
    "#     random_seed=42,\n",
    "#     verbose=0,\n",
    "#     cat_features=cat_features_idx,\n",
    "#     allow_writing_files=False\n",
    "# )\n",
    "\n",
    "# # -----------------------------\n",
    "# # Parameter Space\n",
    "# # -----------------------------\n",
    "# param_dist = {\n",
    "#     'classifier__depth': [4, 6, 8, 10],\n",
    "#     'classifier__learning_rate': [0.03, 0.05, 0.01, 0.1],\n",
    "#     'classifier__iterations': [200, 300, 500, 800],\n",
    "#     'classifier__l2_leaf_reg': [3, 5, 10],\n",
    "#     'classifier__border_count': [64, 128]\n",
    "# }\n",
    "\n",
    "# # -----------------------------\n",
    "# # CV Strategy\n",
    "# # -----------------------------\n",
    "# cv = StratifiedKFold(\n",
    "#     n_splits=5,\n",
    "#     shuffle=True,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # -----------------------------\n",
    "# # Randomized Search\n",
    "# # -----------------------------\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=cb,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=15,\n",
    "#     scoring='f1',\n",
    "#     cv=cv,\n",
    "#     n_jobs=-1,\n",
    "#     random_state=42,\n",
    "#     verbose=2,\n",
    "#     refit=True\n",
    "# )\n",
    "\n",
    "# # -----------------------------\n",
    "# # Train\n",
    "# # -----------------------------\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # -----------------------------\n",
    "# # Best Model & Parameters\n",
    "# # -----------------------------\n",
    "# best_model_cb = random_search.best_estimator_\n",
    "\n",
    "# print(\"\\nBest F1 Score (CV):\", random_search.best_score_)\n",
    "# print(\"\\nBest Parameters:\")\n",
    "# for k, v in random_search.best_params_.items():\n",
    "#     print(f\"{k}: {v}\")\n",
    "\n",
    "# # -----------------------------\n",
    "# # Train & Test Evaluation\n",
    "# # -----------------------------\n",
    "# y_train_pred = best_model_cb.predict(X_train)\n",
    "# print(\"\\nTraining F1 Score:\", f1_score(y_train, y_train_pred))\n",
    "\n",
    "# y_test_pred = best_model_cb.predict(X_test)\n",
    "# print(\"Test F1 Score:\", f1_score(y_test, y_test_pred))\n",
    "\n",
    "# print(\"\\nConfusion Matrix [[TN FP]\\n [FN TP]]:\")\n",
    "# print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "404ef439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Fraud Detection\\.venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:09:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best F1 Score (CV): 0.8280663013851912\n",
      "\n",
      "Best Parameters:\n",
      "classifier__subsample: 0.7\n",
      "classifier__reg_lambda: 10\n",
      "classifier__reg_alpha: 0\n",
      "classifier__n_estimators: 200\n",
      "classifier__min_child_weight: 5\n",
      "classifier__max_depth: 5\n",
      "classifier__learning_rate: 0.02\n",
      "classifier__gamma: 0.5\n",
      "classifier__colsample_bytree: 0.7\n",
      "\n",
      "Train F1 Score: 0.8354600402955004\n",
      "Test F1 Score: 0.7956403269754768\n",
      "\n",
      "Confusion Matrix [[TN FP]\n",
      "                  [FN TP]]:\n",
      "[[19779    19]\n",
      " [   56   146]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# -----------------------------\n",
    "# Parameter Space\n",
    "# -----------------------------\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [200, 300],\n",
    "    'classifier__max_depth': [3, 4, 5],\n",
    "    'classifier__learning_rate': [0.02, 0.03],\n",
    "    'classifier__subsample': [0.6, 0.7, 0.8],\n",
    "    'classifier__colsample_bytree': [0.6, 0.7],\n",
    "    'classifier__min_child_weight': [5, 10, 20],\n",
    "    'classifier__gamma': [0.1, 0.3, 0.5],\n",
    "    'classifier__reg_lambda': [1, 5, 10],\n",
    "    'classifier__reg_alpha': [0, 1, 5]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Base Model\n",
    "# -----------------------------\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',     # F1 is used in CV, not here\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Pipeline\n",
    "# -----------------------------\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb)\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Randomized Search\n",
    "# -----------------------------\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Train\n",
    "# -----------------------------\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# Best Model & Parameters\n",
    "# -----------------------------\n",
    "best_model_xgb = random_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest F1 Score (CV):\", random_search.best_score_)\n",
    "print(\"\\nBest Parameters:\")\n",
    "for k, v in random_search.best_params_.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Train and Test Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "# Train\n",
    "y_train_pred = best_model_xgb.predict(X_train)\n",
    "print(\"\\nTrain F1 Score:\", f1_score(y_train, y_train_pred))\n",
    "\n",
    "# Test\n",
    "y_test_pred = best_model_xgb.predict(X_test)\n",
    "print(\"Test F1 Score:\", f1_score(y_test, y_test_pred))\n",
    "\n",
    "print(\"\"\"\\nConfusion Matrix [[TN FP]\n",
    "                  [FN TP]]:\"\"\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b350225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Fraud Detection\\.venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:09:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train f1 score: 0.8354600402955004\n",
      "test f1 score: 0.8021978021978022\n",
      "\n",
      "confusion_matrix:\n",
      " [[19782    16]\n",
      " [   56   146]]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic', eval_metric='logloss', random_state=42, n_jobs=-1, tree_method='hist', scale_pos_weight=scale_pos_weight,\n",
    "    use_label_encoder=False, \n",
    "    subsample= 0.7,\n",
    "    reg_lambda= 10,\n",
    "    reg_alpha= 0,\n",
    "    n_estimators= 200,\n",
    "    min_child_weight= 5,\n",
    "    max_depth= 5,\n",
    "    learning_rate= 0.02,\n",
    "    gamma= 0.5,\n",
    "    colsample_bytree= 0.7\n",
    ")\n",
    "\n",
    "xgbp = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb)\n",
    "])\n",
    "\n",
    "xgbp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgbp.predict(X_train)\n",
    "print(\"train f1 score:\", f1_score(y_train, y_pred))\n",
    "\n",
    "y_prob = xgbp.predict_proba(X_test)[:,1]\n",
    "y_pred = (y_prob >= 0.54).astype(int)    # best_threshold = 0.54\n",
    "print(\"test f1 score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nconfusion_matrix:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be3e7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test f1 score for threshold 0.45: 0.7913279132791328\n",
      "correspondin confusion_matrix:\n",
      " [[19777    21]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.46: 0.7934782608695652\n",
      "correspondin confusion_matrix:\n",
      " [[19778    20]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.47: 0.7956403269754768\n",
      "correspondin confusion_matrix:\n",
      " [[19779    19]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.48: 0.7956403269754768\n",
      "correspondin confusion_matrix:\n",
      " [[19779    19]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.49: 0.7956403269754768\n",
      "correspondin confusion_matrix:\n",
      " [[19779    19]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.50: 0.7956403269754768\n",
      "correspondin confusion_matrix:\n",
      " [[19779    19]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.51: 0.7956403269754768\n",
      "correspondin confusion_matrix:\n",
      " [[19779    19]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.52: 0.8\n",
      "correspondin confusion_matrix:\n",
      " [[19781    17]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.53: 0.8\n",
      "correspondin confusion_matrix:\n",
      " [[19781    17]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.54: 0.8021978021978022\n",
      "correspondin confusion_matrix:\n",
      " [[19782    16]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.55: 0.8021978021978022\n",
      "correspondin confusion_matrix:\n",
      " [[19782    16]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.56: 0.8021978021978022\n",
      "correspondin confusion_matrix:\n",
      " [[19782    16]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.57: 0.8021978021978022\n",
      "correspondin confusion_matrix:\n",
      " [[19782    16]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.58: 0.8021978021978022\n",
      "correspondin confusion_matrix:\n",
      " [[19782    16]\n",
      " [   56   146]]\n",
      "\n",
      "test f1 score for threshold 0.59: 0.8021978021978022\n",
      "correspondin confusion_matrix:\n",
      " [[19782    16]\n",
      " [   56   146]]\n"
     ]
    }
   ],
   "source": [
    "y_prob = xgbp.predict_proba(X_test)[:,1]\n",
    "for i in range(45,60):\n",
    "    y_pred = (y_prob >= 0.01*i).astype(int)\n",
    "    print(f\"\\ntest f1 score for threshold {0.01*i:.2f}: {f1_score(y_test, y_pred)}\")\n",
    "    print(\"correspondin confusion_matrix:\\n\",confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
