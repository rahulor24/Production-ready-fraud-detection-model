{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7139914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/fraud_transactions.csv\")\n",
    "X = df.drop('fraud_flag', axis=1)\n",
    "y = df['fraud_flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05c1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# currency conversion\n",
    "class CurrencyConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rates=None, base_currency=\"INR\"):\n",
    "        if rates is None:\n",
    "            rates = {\"INR\": 1.0, \"USD\": 83.0, \"EUR\": 90.0}\n",
    "        self.rates = rates\n",
    "        self.base_currency = base_currency\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"amount_converted\"] = X.apply(\n",
    "            lambda row: row[\"amount\"] * self.rates.get(row[\"currency\"], 1.0), axis=1\n",
    "        )\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"Add 'amount_converted' to the feature names\"\"\"\n",
    "        if input_features is None:\n",
    "            input_features = []\n",
    "        # Return original features + new feature\n",
    "        output_features = list(input_features) + ['amount_converted']\n",
    "        return np.asarray(output_features, dtype=object)\n",
    "\n",
    "\n",
    "# typo fixing   \n",
    "class TypoFixer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column='merchant_category', typo_map=None):\n",
    "        if typo_map is None:\n",
    "            typo_map = {'Groceires': 'Groceries'}\n",
    "        self.column = column\n",
    "        self.typo_map = typo_map\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if self.column in X.columns:\n",
    "            X[self.column] = X[self.column].replace(self.typo_map)\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"Feature names unchanged - just fixing typos\"\"\"\n",
    "        if input_features is None:\n",
    "            return np.array([self.column], dtype=object)\n",
    "        return np.asarray(input_features, dtype=object)\n",
    "    \n",
    "\n",
    "# outlier clipping\n",
    "class OutlierClipper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=None, lower_quantile=0.01, upper_quantile=0.99):\n",
    "        self.features = features\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "        self.bounds = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.features:\n",
    "            q_low = X[col].quantile(self.lower_quantile)\n",
    "            q_high = X[col].quantile(self.upper_quantile)\n",
    "            self.bounds[col] = (q_low, q_high)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, (low, high) in self.bounds.items():\n",
    "            X[col] = X[col].clip(lower=low, upper=high)\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"Feature names unchanged - just clipping values\"\"\"\n",
    "        if input_features is None:\n",
    "            return np.asarray(self.features, dtype=object)\n",
    "        return np.asarray(input_features, dtype=object)\n",
    "    \n",
    "\n",
    "# Define Feature Groups\n",
    "num_features = [\n",
    "    \"amount_converted\", \"velocity\", \"ip_risk_score\", \"customer_age\",\n",
    "    \"account_tenure\", \"geo_distance\", \"merchant_risk_score\", \"failed_login_attempts\"\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    \"currency\", \"merchant_category\", \"transaction_type\", \"channel\", \"location\"\n",
    "]\n",
    "\n",
    "bin_features = [\"card_present\", \"is_international\"]\n",
    "\n",
    "\n",
    "# Pipelines for Each Feature Type\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    (\"outlier_clipper\", OutlierClipper(features=num_features)),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"typo_fixer\", TypoFixer()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "cat_pipeline_catboost = Pipeline([\n",
    "    (\"typo fixer\", TypoFixer()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\"))\n",
    "])\n",
    "\n",
    "# Binary pipeline\n",
    "bin_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\"))\n",
    "])\n",
    "\n",
    "\n",
    "# Full Preprocessing Pipeline\n",
    "preprocessor = Pipeline([\n",
    "    (\"currency_converter\", CurrencyConverter()),\n",
    "    (\"transformer\", ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_features),\n",
    "        (\"cat\", cat_pipeline, cat_features),\n",
    "        (\"bin\", bin_pipeline, bin_features)\n",
    "    ]))\n",
    "])\n",
    "\n",
    "preprocessor_catboost = Pipeline([\n",
    "    (\"currency_converter\", CurrencyConverter()),\n",
    "    (\"transformer\", ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_features),\n",
    "        (\"cat\", cat_pipeline_catboost, cat_features),\n",
    "        (\"bin\", bin_pipeline, bin_features)\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a352e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Fraud Detection\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:490: FitFailedWarning: \n",
      "24 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\Fraud Detection\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\Fraud Detection\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\Fraud Detection\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 447, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Projects\\Fraud Detection\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1137: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.847929          nan\n",
      "        nan 0.84712246        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19798\n",
      "           1       0.93      0.72      0.81       202\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.96      0.86      0.91     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "[[19787    11]\n",
      " [   56   146]]\n",
      "OOB Score: 0.9972625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, ParameterSampler, StratifiedKFold\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1, oob_score=True)\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=parameters,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scoring='f1'\n",
    ")\n",
    "# Full pipeline with model\n",
    "model_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", rf_random)\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "# Evaluate the model\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "y_prob = model_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\"\"\\nConfusion matrix: [[TN FP]\n",
    "                   [FN TP]]\"\"\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nOOB Score:\", model_pipeline.named_steps['classifier'].best_estimator_.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import ParameterSampler, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "param_grid_catboost = {\n",
    "    \"iterations\": [200, 500],\n",
    "    \"depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"l2_leaf_reg\": [1, 3, 5]\n",
    "}\n",
    "\n",
    "best_score = -np.inf\n",
    "best_model = None\n",
    "\n",
    "# transform training data\n",
    "X_trf = preprocessor_catboost.fit_transform(X_train)\n",
    "feature_names = preprocessor_catboost.named_steps[\"transformer\"].get_feature_names_out()\n",
    "X_train_transformed = pd.DataFrame(X_trf, columns=feature_names)\n",
    "\n",
    "# identify categorical features for CatBoost\n",
    "catboost_features = [col for col in X_train_transformed.columns.tolist() if col.startswith(\"cat_\")]\n",
    "\n",
    "# stratified k-fold cv\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for params in ParameterSampler(param_grid_catboost, n_iter=5, random_state=42):\n",
    "    \n",
    "    cv_scores = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X_train_transformed, y_train):\n",
    "        X_train_cv, X_val_cv = X_train_transformed.iloc[train_index], X_train_transformed.iloc[val_index]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        **params,\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"F1\",\n",
    "        class_weights=[1, 10],\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "        cat_features=[X_train_transformed.columns.get_loc(col) for col in catboost_features]\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_cv, y_train_cv)\n",
    "    y_pred = model.predict(X_val_cv)\n",
    "\n",
    "    cv_scores.append(f1_score(y_val_cv, y_pred))\n",
    "\n",
    "    if np.mean(cv_scores) > best_score:\n",
    "        best_score = np.mean(cv_scores)\n",
    "        best_model = model\n",
    "\n",
    "print(\"Best CatBoost Model:\")\n",
    "print(\"Best CV F1:\", best_score)\n",
    "print(\"Best params:\", best_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a55ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "\n",
      "Best F1 Score (CV): 0.8474077348318468\n",
      "\n",
      "Best Parameters:\n",
      "classifier__n_estimators: 200\n",
      "classifier__min_samples_split: 5\n",
      "classifier__min_samples_leaf: 4\n",
      "classifier__max_depth: 10\n",
      "training f1 score: 0.8512396694214877\n",
      "training f1 score: 0.8133704735376045\n",
      "\n",
      "Confusion Matrix [[TN FP]\n",
      " [FN TP]]:\n",
      "[[19787    11]\n",
      " [   56   146]]\n",
      "\n",
      "OOB Score: 0.99725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# Parameter Space\n",
    "# -----------------------------\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Base Model\n",
    "# -----------------------------\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Pipeline\n",
    "# -----------------------------\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', rf)\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Randomized Search\n",
    "# -----------------------------\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    refit=True   # refit best model automatically\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Train\n",
    "# -----------------------------\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# Best Model & Parameters\n",
    "# -----------------------------\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest F1 Score (CV):\", random_search.best_score_)\n",
    "print(\"\\nBest Parameters:\")\n",
    "for k, v in random_search.best_params_.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Train and Test Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "y_pred = best_model.predict(X_train)\n",
    "print(\"\\ntraining f1 score:\", f1_score(y_train, y_pred))\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"training f1 score:\", f1_score(y_test, y_pred))\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix [[TN FP]\\n [FN TP]]:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# -----------------------------\n",
    "# OOB Score (Only if bootstrap=True)\n",
    "# -----------------------------\n",
    "rf_best = best_model.named_steps['classifier']\n",
    "\n",
    "if rf_best.bootstrap:\n",
    "    print(\"\\nOOB Score:\", rf_best.oob_score_)\n",
    "else:\n",
    "    print(\"\\nOOB Score: Not available (bootstrap=False)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa286575",
   "metadata": {},
   "source": [
    "| Pattern           | Meaning              |\n",
    "| ----------------- | -------------------- |\n",
    "| Train ≫ CV ≈ Test | Overfitting          |\n",
    "| Train ≈ CV ≈ Test | Healthy              |\n",
    "| CV ≫ Test         | Data leakage / shift |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa051c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training f1 score: 0.8512396694214877\n",
      "testing f1 score: 0.8133704735376045\n",
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19798\n",
      "           1       0.93      0.72      0.81       202\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.96      0.86      0.91     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_depth=10,\n",
    "                            random_state=42, class_weight='balanced', n_jobs=-1, oob_score=True)\n",
    "\n",
    "rfp = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', rf)\n",
    "])\n",
    "\n",
    "rfp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfp.predict(X_train)\n",
    "print(\"training f1 score:\", f1_score(y_train, y_pred))\n",
    "\n",
    "y_pred = rfp.predict(X_test)\n",
    "print(\"testing f1 score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"classification_report\", classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09a30252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b58d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_tr, y_tr)\n",
    "y_val_probs = best_model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "104539b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.7614023318402273\n",
      "Validation F1: 0.8591065287152962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "print(\"Validation F1:\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b6859fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.8056338028169014\n"
     ]
    }
   ],
   "source": [
    "y_test_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_probs >= best_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"Test F1:\", f1_score(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
